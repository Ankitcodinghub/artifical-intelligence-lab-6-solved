# artifical-intelligence-lab-6-solved
**TO GET THIS SOLUTION VISIT:** [Artifical Intelligence Lab 6 Solved](https://www.ankitcodinghub.com/product/artifical-intelligence-inteligenta-artificiala-solved-2/)


---

📩 **If you need this solution or have special requests:** **Email:** ankitcoding@gmail.com  
📱 **WhatsApp:** +1 419 877 7882  
📄 **Get a quote instantly using this form:** [Ask Homework Questions](https://www.ankitcodinghub.com/services/ask-homework-questions/)

*We deliver fast, professional, and affordable academic help.*

---

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;117646&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;2&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;5&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;5\/5 - (2 votes)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;Artifical Intelligence Lab 6 Solved&quot;,&quot;width&quot;:&quot;138&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">

<div class="kksr-stars">

<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>

<div class="kksr-stars-active" style="width: 138px;">
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>


<div class="kksr-legend" style="font-size: 19.2px;">
            5/5 - (2 votes)    </div>
    </div>
Laborator 9 și 10. Reinforcement Learning

Temă

Considerăm un agent care se poate deplasa într-un mediu (un grid de dimensiuni nxn). Agentul se poate deplasa în direcția sus, jos, stânga sau dreapta. Agentul poate merge pe gheață. În unele locuri, gheața este subțire și se poate sparge. Dacă agentul ajunge într-o astfel de locație, atunci acesta moare.

Spre exemplu, putem avea următoarea configurație (4×4, iar pătratele albastre reprezintă gheața care se poate sparge):

Având un punct de start, scopul agentului este să ajungă la destinație. În exemplul de mai sus, punctul de start este pătratul stânga-sus, iar destinația este pătratul dreapta-jos. Când agentul ajunge la destinație, recompensa este egală cu 1, altfel este 0.

I. Implementarea algoritmului Q-learning

a. (0.1p) inițializarea tabelei Q, a parametrilor algoritmului și a stării inițiale

b. (0.1p) pentru o stare s, identifică starea următoare s’ prin aplicarea unei acțiuni a

c. (0.8p) implementează algoritmul Q-learning pentru a identifica drumul pe care trebuiesă-l parcurgă agentul

– selectează acțiunea cu cea mai mare valoare Q din starea s’

– actualizează valorile Q

– actualizează starea curentă

– repetă

II. (0.6p) Utilizarea unei rețele neuronale pentru a aproxima funcția Q / Implementarea algoritmului Deep Q-learning

Observație: se poate folosi mediul Open AI gym https://gym.openai.com/

Pentru săptămâna 6-12 decembrie: punctele I.a, I.b

Pentru săptămâna 13-19 decembrie: punctul I.c Pentru săptămâna 3-9 ianuarie: punctul II

Documentație:

Secțiunea 6.5 Q-learning: Off-policy TD Control http://incompleteideas.net/book/ebook/node65.html

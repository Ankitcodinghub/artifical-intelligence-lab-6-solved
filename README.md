# artifical-intelligence-lab-6-solved
**TO GET THIS SOLUTION VISIT:** [Artifical Intelligence Lab 6 Solved](https://www.ankitcodinghub.com/product/artifical-intelligence-inteligenta-artificiala-solved-2/)


---

ğŸ“© **If you need this solution or have special requests:** **Email:** ankitcoding@gmail.com  
ğŸ“± **WhatsApp:** +1 419 877 7882  
ğŸ“„ **Get a quote instantly using this form:** [Ask Homework Questions](https://www.ankitcodinghub.com/services/ask-homework-questions/)

*We deliver fast, professional, and affordable academic help.*

---

<h2>Description</h2>



<div class="kk-star-ratings kksr-auto kksr-align-center kksr-valign-top" data-payload="{&quot;align&quot;:&quot;center&quot;,&quot;id&quot;:&quot;117646&quot;,&quot;slug&quot;:&quot;default&quot;,&quot;valign&quot;:&quot;top&quot;,&quot;ignore&quot;:&quot;&quot;,&quot;reference&quot;:&quot;auto&quot;,&quot;class&quot;:&quot;&quot;,&quot;count&quot;:&quot;2&quot;,&quot;legendonly&quot;:&quot;&quot;,&quot;readonly&quot;:&quot;&quot;,&quot;score&quot;:&quot;5&quot;,&quot;starsonly&quot;:&quot;&quot;,&quot;best&quot;:&quot;5&quot;,&quot;gap&quot;:&quot;4&quot;,&quot;greet&quot;:&quot;Rate this product&quot;,&quot;legend&quot;:&quot;5\/5 - (2 votes)&quot;,&quot;size&quot;:&quot;24&quot;,&quot;title&quot;:&quot;Artifical Intelligence Lab 6 Solved&quot;,&quot;width&quot;:&quot;138&quot;,&quot;_legend&quot;:&quot;{score}\/{best} - ({count} {votes})&quot;,&quot;font_factor&quot;:&quot;1.25&quot;}">

<div class="kksr-stars">

<div class="kksr-stars-inactive">
            <div class="kksr-star" data-star="1" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="2" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="3" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="4" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" data-star="5" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>

<div class="kksr-stars-active" style="width: 138px;">
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
            <div class="kksr-star" style="padding-right: 4px">


<div class="kksr-icon" style="width: 24px; height: 24px;"></div>
        </div>
    </div>
</div>


<div class="kksr-legend" style="font-size: 19.2px;">
            5/5 - (2 votes)    </div>
    </div>
Laborator 9 È™i 10. Reinforcement Learning

TemÄƒ

ConsiderÄƒm un agent care se poate deplasa Ã®ntr-un mediu (un grid de dimensiuni nxn). Agentul se poate deplasa Ã®n direcÈ›ia sus, jos, stÃ¢nga sau dreapta. Agentul poate merge pe gheaÈ›Äƒ. Ãn unele locuri, gheaÈ›a este subÈ›ire È™i se poate sparge. DacÄƒ agentul ajunge Ã®ntr-o astfel de locaÈ›ie, atunci acesta moare.

Spre exemplu, putem avea urmÄƒtoarea configuraÈ›ie (4Ã—4, iar pÄƒtratele albastre reprezintÄƒ gheaÈ›a care se poate sparge):

AvÃ¢nd un punct de start, scopul agentului este sÄƒ ajungÄƒ la destinaÈ›ie. Ãn exemplul de mai sus, punctul de start este pÄƒtratul stÃ¢nga-sus, iar destinaÈ›ia este pÄƒtratul dreapta-jos. CÃ¢nd agentul ajunge la destinaÈ›ie, recompensa este egalÄƒ cu 1, altfel este 0.

I. Implementarea algoritmului Q-learning

a. (0.1p) iniÈ›ializarea tabelei Q, a parametrilor algoritmului È™i a stÄƒrii iniÈ›iale

b. (0.1p) pentru o stare s, identificÄƒ starea urmÄƒtoare sâ€™ prin aplicarea unei acÈ›iuni a

c. (0.8p) implementeazÄƒ algoritmul Q-learning pentru a identifica drumul pe care trebuiesÄƒ-l parcurgÄƒ agentul

â€“ selecteazÄƒ acÈ›iunea cu cea mai mare valoare Q din starea sâ€™

â€“ actualizeazÄƒ valorile Q

â€“ actualizeazÄƒ starea curentÄƒ

â€“ repetÄƒ

II. (0.6p) Utilizarea unei reÈ›ele neuronale pentru a aproxima funcÈ›ia Q / Implementarea algoritmului Deep Q-learning

ObservaÈ›ie: se poate folosi mediul Open AI gym https://gym.openai.com/

Pentru sÄƒptÄƒmÃ¢na 6-12 decembrie: punctele I.a, I.b

Pentru sÄƒptÄƒmÃ¢na 13-19 decembrie: punctul I.c Pentru sÄƒptÄƒmÃ¢na 3-9 ianuarie: punctul II

DocumentaÈ›ie:

SecÈ›iunea 6.5 Q-learning: Off-policy TD Control http://incompleteideas.net/book/ebook/node65.html
